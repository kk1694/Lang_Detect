{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "My aim here is to build a language classifier for EU languages.\n",
    "\n",
    "Proposed Approach:\n",
    "1. Inspect test set\n",
    "1. Create dataset for training / validation\n",
    "1. Train / valid split\n",
    "1. Numericalize\n",
    "1. Build language classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "import dill  # Better version of pickle, able to save objects with lambda expressions\n",
    "import copy  # Used for making a deep copy of a model\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')  # Directory for all data and temporary files\n",
    "# Note: to run on the whole training set, specify PATH/'train' as the path.\n",
    "# However, since that corpus is huge, the learning rate will have to be reduced.\n",
    "# Also, the whole corpus will need a much higher training time.\n",
    "TRAIN = PATH/'train_sampl'  # Directory for training text\n",
    "TEST_FN = PATH/'test'  # Filename for test text\n",
    "PATH_TMP = PATH/'tmp'  # Temporary directory to save progress\n",
    "\n",
    "MIN_FREQ = 3  # We'll replace words with lower frequency with unknown\n",
    "SEQ_LEN = 32  # Length of the sequences passed into our GRU\n",
    "\n",
    "BS = 512  # Batch size for our RNN\n",
    "\n",
    "EMB_SZ = 50  # Dimension of word embeddings\n",
    "HIDDEN_SZ = 250  # Hidden layer dimension of the GRU\n",
    "EMB_DROP = 0.25  # Dropout applied to embeddings\n",
    "LAYER_DROP = 0.25  # Dropout applied after GRU\n",
    "\n",
    "# List of languages\n",
    "LANGS = list(map(lambda x: x.name, list(TRAIN.iterdir())))\n",
    "\n",
    "assert torch.cuda.is_available()  # Notebook is written for GPU computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TMP.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarify Goal\n",
    "\n",
    "Let's first have a look at the test set we are trying to predict. It looks like a simple text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>en</td>\n",
       "      <td>(BG) Thank you, Mr President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>en</td>\n",
       "      <td>(EL) Madam President, I agree and recognise Tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>en</td>\n",
       "      <td>(FI) Madam President, firstly, I would like to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>en</td>\n",
       "      <td>(FI) Mr President, the Treaty of Lisbon will r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>en</td>\n",
       "      <td>(FR) Madam President, one of the priorities of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "4992    en                      (BG) Thank you, Mr President.\n",
       "4993    en  (EL) Madam President, I agree and recognise Tu...\n",
       "4994    en  (FI) Madam President, firstly, I would like to...\n",
       "4995    en  (FI) Mr President, the Treaty of Lisbon will r...\n",
       "4996    en  (FR) Madam President, one of the priorities of..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(TEST_FN, sep = '\\t', lineterminator='\\n', header=None)\n",
    "test.rename({0:'label', 1:'text'}, axis = 1, inplace=True)\n",
    "test[test['label'] == 'en'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going any further, let's apply some preprocessing. In particular, I apply the following steps:\n",
    "1. Remove uninformative meta-comments, such as who is speaking.\n",
    "1. Replace numbers with a generic *num* token. After all, the specific number shouldn't affect the classification results.\n",
    "1. Create a special end-of-sentence (*eos*) token.\n",
    "1. Replace all punctuation with a special *punc* token. \n",
    "1. Collapse adjecent white space. In other words, '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;' becomes '&nbsp;'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['text'].apply(utils.preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check a random English and German sentence after pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<punct> BG <punct> Thank you <punct> Mr President <eos>\n",
      "---\n",
      "<punct> BG <punct> Herr Kommissar <eos> Das Dokument <punct> das vom Europ√§ischen Parlament angenommen werden soll <punct> ist in der Tat sehr wichtig <eos>\n"
     ]
    }
   ],
   "source": [
    "print(test[test['label']=='en'].iloc[0][\"text\"])\n",
    "print('---')\n",
    "print(test[test['label']=='de'].iloc[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20828.000000</td>\n",
       "      <td>20828.000000</td>\n",
       "      <td>20828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.113837</td>\n",
       "      <td>26.071922</td>\n",
       "      <td>175.205541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.851456</td>\n",
       "      <td>25.298060</td>\n",
       "      <td>167.062078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>224.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>2184.000000</td>\n",
       "      <td>14069.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_count    word_count           len\n",
       "count    20828.000000  20828.000000  20828.000000\n",
       "mean         1.113837     26.071922    175.205541\n",
       "std          0.851456     25.298060    167.062078\n",
       "min          1.000000      3.000000     22.000000\n",
       "25%          1.000000     15.000000     99.000000\n",
       "50%          1.000000     23.000000    154.000000\n",
       "75%          1.000000     33.000000    224.000000\n",
       "max         77.000000   2184.000000  14069.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count(x): return len(x.split())\n",
    "def sentence_count(x): return len(x.split('<eos>')) - 1\n",
    "test['text'].apply([sentence_count, word_count, len]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target for our classification model has the following characteristics:\n",
    "1. The vast majority of examples are a single sentence.\n",
    "1. Most of the time, we have a decent number of words (15-33) to predict a language.\n",
    "1. However, we can have as little as 3 words. This might pose a challenge if those words are not language-specific.\n",
    "1. Content-wise, most sentences seem to be about parliamentary proceedings (my guess: proceedings of the EUP for more recent years)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Training/Validation Data\n",
    "\n",
    "Our training set is of similar content, but in different format. Specifically, we don't have sentence-level chunks as in our test set, instead, we have files with different number of sentences. So we need to create a dataframe that resembles our test set.\n",
    "\n",
    "First, we take all files for a language and concatenate them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<CHAPTER ID=\"010\">\\nPetitions: see Minutes\\n<CHAPTER ID=\"010\">\\nPreventing trafficking in human beings (debate) \\n<SPEAKER ID=\"209\" NAME=\"President\">\\nThe next item is the debate on\\n<P>\\nthe oral question t'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# An example with English, we'll do all processing steps for all files below.\n",
    "exampl = utils.concat_docs('en', TRAIN)\n",
    "exampl[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the same pre-processing as we did to our test set, and turn the whole corpus into a list of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Petitions <punct> see Minutes <eos>',\n",
       " 'Preventing trafficking in human beings <punct> debate <punct> <eos>',\n",
       " 'The next item is the debate on <eos>']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example continued.\n",
    "exampl = utils.txt2list(utils.preprocess(exampl[:1000]))\n",
    "exampl[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one last step we do. The test set had occasionally (although not often) multiple sentences. So we want to have, occasionally, multiple sentences in our training set as well. We can accomplish this by concatenating adjecent sentences together with a small probability (p = 0.02).\n",
    "\n",
    "Let's apply all the above steps to all languages. I will also put everything into a dataframe with an extra column giving the language label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fi  et  it  lt  pt  lv  nl  pl  bg  en  sk  fr  da  hu  cs  sl  es  el  ro  de  sv "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fi</td>\n",
       "      <td>Neuvoston toimittamat sopimustekstit &lt;punct&gt; k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fi</td>\n",
       "      <td>p√∂yt√§kirja &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fi</td>\n",
       "      <td>Suulliset kysymykset ja kirjalliset kannanotot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fi</td>\n",
       "      <td>p√∂yt√§kirja &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fi</td>\n",
       "      <td>Parlamentin puhemiehen puhe &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0    fi  Neuvoston toimittamat sopimustekstit <punct> k...\n",
       "1    fi                                   p√∂yt√§kirja <eos>\n",
       "2    fi  Suulliset kysymykset ja kirjalliset kannanotot...\n",
       "3    fi                                   p√∂yt√§kirja <eos>\n",
       "4    fi                  Parlamentin puhemiehen puhe <eos>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []  # List to store data frames\n",
    "for lang in LANGS:\n",
    "    print(' '+lang+' ', end = \"\")\n",
    "    txt = utils.concat_docs(lang, TRAIN)  # Concatenate all files\n",
    "    txt = utils.preprocess(txt)  # Apply preprocessing described in test section\n",
    "    txt = utils.txt2list(txt)  # Convert to list\n",
    "    txt = utils.concat_random_sent(txt, p = 0.02)  # Concatenate random adjecent sentences\n",
    "    temp_df = pd.DataFrame({'text':txt})  \n",
    "    temp_df['label'] = lang\n",
    "    dfs.append(temp_df)\n",
    "df = pd.concat(dfs)[['label', 'text']]\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.140519e+06</td>\n",
       "      <td>2.140519e+06</td>\n",
       "      <td>2.140519e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.020188e+00</td>\n",
       "      <td>2.499734e+01</td>\n",
       "      <td>1.649135e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.421484e-01</td>\n",
       "      <td>1.657229e+01</td>\n",
       "      <td>1.098704e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>8.700000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "      <td>1.440000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>2.180000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>7.910000e+02</td>\n",
       "      <td>5.184000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_count    word_count           len\n",
       "count    2.140519e+06  2.140519e+06  2.140519e+06\n",
       "mean     1.020188e+00  2.499734e+01  1.649135e+02\n",
       "std      1.421484e-01  1.657229e+01  1.098704e+02\n",
       "min      1.000000e+00  2.000000e+00  9.000000e+00\n",
       "25%      1.000000e+00  1.300000e+01  8.700000e+01\n",
       "50%      1.000000e+00  2.200000e+01  1.440000e+02\n",
       "75%      1.000000e+00  3.300000e+01  2.180000e+02\n",
       "max      4.000000e+00  7.910000e+02  5.184000e+03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply([sentence_count, word_count, len]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our resulting dataframe looks very similar to our test set. \n",
    "\n",
    "One difference: wee don't go quite as high on the maximum words and sentences. That's not going to matter though, as later on I will truncate all text at 32 words anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(dfs, temp_df, txt, exampl)\n",
    "dill.dump(df, open(PATH_TMP/'df.pickle', mode = 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = dill.load(open(PATH_TMP/'df.pickle', mode = 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split\n",
    "\n",
    "Let's split the data for training and validation. No big surprises here.\n",
    "\n",
    "I use 1% of the data as validation. If that seems unusual, note that our dataset contains ~2 million rows, so our validation set will contain ~20k. I'm only using the validation set to monitor performance and check for over-fitting; 20k examples are more than enough for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2140519"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nl', 'en', 'sv', ..., 'pl', 'et', 'el'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(np.array(df['text']), np.array(df['label']), \n",
    "                                                  test_size=0.01, random_state=42)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalize\n",
    "\n",
    "We need to turn our words into intiger indices. Later we use these indices to look up the embeddings for each word.\n",
    "\n",
    "Let's start by counting the number of times a word appears in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "[('<punct>', 4180363),\n",
       " ('<eos>', 2161855),\n",
       " ('de', 1033681),\n",
       " ('a', 526222),\n",
       " ('<num>', 423048),\n",
       " ('la', 391229),\n",
       " ('en', 371657),\n",
       " ('que', 341022),\n",
       " ('in', 296137),\n",
       " ('i', 254115)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for row in tqdm(X_train, position=0, leave=False): words.update(row.split())\n",
    "words.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No big surprises: the most frequent words are punctuation, end-of-sentence tokens, articles and prepositions.\n",
    "\n",
    "Now we drop all words under 3 (what is specified under MIN_FREQ). Doing so is to make our embedding matrix smaller. Decreasing MIN_FREQ will increase the accuracy of our model, at a higher memory and computation cost.\n",
    "\n",
    "We also add two special tokens: unknown (*unk*) and padding (*pad*). Unknown is any word not appearing in our list. These are any new words in our test or validation set, as well as the words we previously dropped due to low frequence. Padding will later be used to make all sequences equal length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "words = {k:v for k, v in tqdm(words.items(), leave = False) if v >= MIN_FREQ}\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "words = ['<unk>','<pad>'] + words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497262"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more than 300k unique words. Now we need to create a mapping from words to integers (and back). I'll use the dictionaries below to do so.\n",
    "\n",
    "Note that unknown is mapped to 0, and padding is mapped to 1 (they are the first two elements by construction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = defaultdict(lambda: 0, {o:i for i,o in enumerate(words)})\n",
    "idx2word = defaultdict(lambda: '<unk>', {i:o for i,o in enumerate(words)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the first sentence of the training set converted into indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49304, 220, 2317, 3826, 6674, 3498, 83, 199, 18214, 192, 2858, 123, 2, 6, 19, 4, 11540, 8, 192, 14042, 6, 19, 4, 192, 83, 1561, 20746, 2, 2080, 4, 11463, 349, 18663, 68, 4, 104192, 19, 34449, 142, 1183, 107, 25036, 3330, 136743, 3]\n"
     ]
    }
   ],
   "source": [
    "print([word2idx[w] for w in X_train[0].split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the above to the whole training set. I also truncate long sentences at 32 words -- that should be more than enough to classify a language, and having more words would needlessly slow down computation time.\n",
    "\n",
    "I also pad sentences that are shorter than 32 with the special padding character. This way, all example are of equal length, making subsequent computations easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2119113, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train = utils.numericalize(X_train, word2idx, maxlen = SEQ_LEN)\n",
    "X_val = utils.numericalize(X_val, word2idx, maxlen = SEQ_LEN)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can alway convert our indices back. Below is our first training example converted back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binnen dit kader dient speciale aandacht te worden besteed aan punt A <punct> <num> van de mededeling en aan paragraaf <num> van de aan te nemen ontwerpresolutie <punct> waarin de wens wordt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.de_numericalize(X_train[:1], idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also replace languages with contiguous integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang2idx = defaultdict(lambda: 0, {o:i for i,o in enumerate(LANGS)})\n",
    "idx2lang = defaultdict(lambda: '<unk>', {i:o for i,o in enumerate(LANGS)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nl' 'en' 'sv' 'nl' 'fr']\n",
      "[ 6  9 20  6 11]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])  # Before\n",
    "y_train = np.array([lang2idx[x] for x in y_train])\n",
    "y_val = np.array([lang2idx[x] for x in y_val])\n",
    "print(y_train[:5])  # After"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH_TMP/'numericalized.pickle', mode = 'wb') as f:\n",
    "    dill.dump([words, vocab_size, word2idx, idx2word, X_train, X_val, y_train, y_val], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(PATH_TMP/'numericalized.pickle', mode = 'rb') as f:\n",
    "#    (words, vocab_size, word2idx, idx2word, X_train, X_val, y_train, y_val) = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time after pre-processing : 2.7283118883768718 mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'Time after pre-processing : {(end - start)/60} mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloaders\n",
    "\n",
    "We take our training and validation data, convert them from numpy arrays to torch tensors, and put them in dataloaders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train).type(torch.int64)\n",
    "y_train = torch.from_numpy(y_train).type(torch.int64)\n",
    "X_val = torch.from_numpy(X_val).type(torch.int64)\n",
    "y_val = torch.from_numpy(y_val).type(torch.int64)\n",
    "\n",
    "train_dl = DataLoader(TensorDataset(X_train, y_train), batch_size=BS, shuffle = True)\n",
    "valid_dl = DataLoader(TensorDataset(X_val, y_val), batch_size=BS, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "Our model is a relatively simple recurrent network. We go through our sentence word by word, look it up in our embedding matrix, and feed it into our GRU. We apply a linear layer to the final output of our GRU, which gives our predictions. \n",
    "\n",
    "![Model Illustration](model_illustration.jpg)\n",
    "\n",
    "I also added dropout for regularization. I applied it at two points: first after our embedding lookup, and then before the final linear layer.\n",
    "\n",
    "Why not use something more complicated (say, a bidirectional LSTM)? It's simply not needed. The task is relatively simple, no need for an overkill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang_Detect(nn.Module):\n",
    "    def __init__(self, emb_sz = EMB_SZ, vocab_size = vocab_size,\n",
    "                 hidden_sz = HIDDEN_SZ, out_sz = len(LANGS), \n",
    "                 emb_drop = EMB_DROP, layer_drop = LAYER_DROP):\n",
    "        super().__init__()\n",
    "        self.hidden_sz = hidden_sz\n",
    "        self.emb = nn.Embedding(vocab_size, emb_sz)\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.emb.weight.data.uniform_(-0.05, 0.05)  # Initialize embeddings\n",
    "        self.gru = nn.GRU(emb_sz, hidden_sz)\n",
    "        self.layer_drop = nn.Dropout(layer_drop)\n",
    "        self.lout = nn.Linear(hidden_sz, out_sz)        \n",
    "                \n",
    "    def forward(self, seq): \n",
    "        bs, _ = seq.shape\n",
    "        h =  torch.zeros(1, bs, self.hidden_sz).cuda()  # Initial empty hidden state\n",
    "        embedded = self.emb(seq).transpose(0, 1)\n",
    "        outputs, _ = self.gru(self.emb_drop(embedded), h)\n",
    "        output = self.lout(self.layer_drop(outputs[-1]))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lang_Detect().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use standard cross-entropy as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model\n",
    "\n",
    "I create a special class that helps with fitting the model. It is model agnostic, and can help fit other pytorch models as well.\n",
    "\n",
    "First a helper function that calculates the loss for a batch, and updates parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(xb, yb, model, loss_func, opt=None):\n",
    "    \n",
    "    '''Calculates the loss for a minibatch, and (if opt is given) updates parameters'''\n",
    "    # Taken from: https://github.com/fastai/fastai_v1/blob/master/dev_nb/001a_nn_basics.ipynb\n",
    "\n",
    "    loss = loss_func(model(xb.cuda()), yb.cuda())\n",
    "    if opt is not None:  # Update parameters\n",
    "        loss.backward(); opt.step(); opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Learner class below has 3 methods to help the fitting process:\n",
    "- lr_find: to find the optimal learning rate,\n",
    "- fit: to fit the model,\n",
    "- predict: to predict on new data,\n",
    "- plot_loss: plot the training loss.\n",
    "\n",
    "The inspiration for this class is the [fast.ai](https://github.com/Gokkulnath/fastai-v0.7) library (version 0.7, now depreciated), which contains similar classes for fitting pytorch models.\n",
    "\n",
    "I use the Adam optimizer with standard settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(object):\n",
    "    \n",
    "    def __init__(self, model, loss_func, train_dl = None, valid_dl = None):\n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.train_dl = train_dl\n",
    "        self.valid_dl = valid_dl\n",
    "        self.losses = []\n",
    "    \n",
    "    def lr_find(self, start = 1e-6, end = 1e3, exp_smooth_param = 0.95):\n",
    "        \n",
    "        '''Learning rate finder, detailed explanation below.'''\n",
    "        \n",
    "        old_state_dict = copy.deepcopy(self.model.state_dict())  # Save old parameters\n",
    "        self.model.train()\n",
    "        lr = start; lrs = []; losses = []; i = 0\n",
    "        for xb,yb in tqdm(self.train_dl, leave = False,\n",
    "                         position = 0):\n",
    "            opt = optim.Adam(self.model.parameters(), lr=lr)\n",
    "            loss, _ = loss_batch(xb, yb, self.model, self.loss_func, opt)\n",
    "            lrs.append(lr), losses.append(loss)\n",
    "            if (lr > end) or (i > 10 and loss > 3*np.mean(losses[:i])):\n",
    "                break  # Stop if losses shoot up higher than the average loss so far\n",
    "            lr *= 1.03; i += 1        \n",
    "        self.losses = losses  # Previous losses aren't relevant for plotting\n",
    "        self.plot_loss(x = lrs, xlog=True, exp_smooth_param = exp_smooth_param)\n",
    "        self.losses = []  # Reset list\n",
    "        # Note: we don't want to keep the parameters, as at the end of the algorithm\n",
    "        # very high learning rates are used, and the loss is high. Hence, we\n",
    "        # reset it\n",
    "        self.model.load_state_dict(old_state_dict)\n",
    "        \n",
    "    def plot_loss(self, x = None, xlog = False, exp_smooth_param = 0.95):\n",
    "        '''Plots training loss. Each datapoint is a mini-batch.'''\n",
    "        # Note: plots losses from all epochs (since the last lr_find call)\n",
    "        \n",
    "        # Use exponental smoothing with parameter exp_smooth_param\n",
    "        y_smooth = utils.exp_smooth(np.array(self.losses), exp_smooth_param)\n",
    "        f, ax = plt.subplots(figsize=(5, 5))\n",
    "        if xlog:  # Use log on both scales\n",
    "            ax.set(yscale = 'log', xscale = 'log')  \n",
    "        else: \n",
    "            ax.set(yscale = 'log')\n",
    "        if x is not None:\n",
    "            ax = plt.plot(x, y_smooth)\n",
    "        else:\n",
    "            ax = plt.plot(y_smooth)     \n",
    "            \n",
    "    def fit(self, lr, epochs):\n",
    "        \n",
    "        '''Fits model for specified number of epochs, with learning rate lr.'''\n",
    "        \n",
    "        opt = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "        \n",
    "            # Fit model to training data\n",
    "            self.model.train()  # Enables dropout\n",
    "            losses, nums = zip(*[loss_batch(xb, yb, self.model, self.loss_func, opt) \n",
    "                                 for xb,yb in tqdm(self.train_dl, leave = False, position = 0)])\n",
    "            train_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "            self.losses = self.losses+list(losses)\n",
    "            \n",
    "            # Apply model to validation data\n",
    "            if self.valid_dl != None:             \n",
    "                self.model.eval()  # Disables dropout\n",
    "                with torch.no_grad():  # No gradient calculations\n",
    "                    \n",
    "                    # Note: loss_batch doesn't update parameters if not supplied with\n",
    "                    # an optimizer. So this loop only calculates the loss.\n",
    "                    losses,nums = zip(*[loss_batch(xb, yb, self.model, self.loss_func)\n",
    "                                        for xb,yb in valid_dl])\n",
    "                    val_loss = np.sum(np.multiply(losses,nums)) / np.sum(nums)\n",
    "                    \n",
    "                    # Also compute validation accuracy\n",
    "                    val_preds = self.predict(self.valid_dl)\n",
    "                    y_val = self.valid_dl.dataset.tensors[1]\n",
    "                    acc = utils.accuracy(val_preds, y_val) \n",
    "                    # Note: in this case, refactoring code means we run the model through\n",
    "                    # the validation set twice. That's okay - the validation set is small.\n",
    "                    \n",
    "                print(f'Epoch {epoch}. Training loss: {train_loss}. ' +\n",
    "                      f'Validation loss: {val_loss}. Accuracy: {acc}')  \n",
    "            else:  \n",
    "                print(f'Epoch {epoch}. Training loss: {train_loss}.')\n",
    "                        \n",
    "    def predict(self, dl):\n",
    "        '''Gives predictions on supplied dataloader, concatenates results.'''\n",
    "        self.model.eval()  # No dropout\n",
    "        with torch.no_grad():  # No gradient calculations\n",
    "            res = [self.model(xb.cuda()).argmax(dim = -1).view(-1) for \n",
    "                   xb, _ in tqdm(dl, leave = False, position = 0)]\n",
    "        return torch.cat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, loss_func, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our untrained model to predict the validation set. As expected, it's about as good as chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.02275063066429973"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = learn.predict(valid_dl)\n",
    "utils.accuracy(preds, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit our model, we have to give it a learning rate. A learning rate that's too high will not converge on a minimum, a learning rate that's too low will take too long to find one.\n",
    "\n",
    "The lr_find method helps us pick a good learning rate, neither too high, nor too low. Originally, the idea was mentioned in [this](https://arxiv.org/abs/1506.01186) paper, a nice blog post explaining the concept is [here](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html).\n",
    "\n",
    "We start fitting our neural net with a very low learning rate (1e-6). Then after each minibatch, we increase it a little (by 3%). We do it until we reach a rate that's too high (1e3), or until our loss sharply increases.\n",
    "\n",
    "What tends to happen: at low learning rates, our loss doesn't improve. At a certain point, it decreases steeply. However, moving past this optimal range, or loss shoots up as we are taking update steps too big.\n",
    "\n",
    "Here is our (smoothed) loss plotted against the learning rate. Note that we don't want to pick the minimum: at that point the learning rate is already too high. Instead we want to pick a point where we are improving at a good rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To err on the safe side, I choose a relatively low rate. Training this network is relatively fast anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4139 [00:00<11:21,  6.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Training loss: 0.10018208339380884. Validation loss: 0.022138595346853557. Accuracy: 0.9937867887508175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4139 [00:00<11:26,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training loss: 0.01785284983413864. Validation loss: 0.019705724541773464. Accuracy: 0.9950948332243297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Training loss: 0.014586188615839497. Validation loss: 0.019980412532123733. Accuracy: 0.9947678221059516\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(lr, 3)\n",
    "dill.dump(learn.model.state_dict(), open(PATH_TMP/'model0.pickle', mode = 'wb'))\n",
    "learn.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are already achieving good results (XXX% accuracy on the validation set). Let's decrease our learning rate by two orders of magnitude and fit just a little more to fine-tune our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4139 [00:00<11:27,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Training loss: 0.012406580897204518. Validation loss: 0.019306764560378758. Accuracy: 0.9949546856021676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4139 [00:00<11:34,  5.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1. Training loss: 0.012085104193215115. Validation loss: 0.019164270048096635. Accuracy: 0.9950481173502757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2. Training loss: 0.011922142346405765. Validation loss: 0.019069904299567935. Accuracy: 0.9950481173502757\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(lr/1e2, 3)\n",
    "dill.dump(learn.model.state_dict(), open(PATH_TMP/'model1.pickle', mode = 'wb'))\n",
    "learn.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time after training : 11.926600913206736 mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'Time after training : {(end - start)/60} mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_test = utils.numericalize(np.array(test['text']), word2idx)\n",
    "y_test = np.array([lang2idx[x] for x in test['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.from_numpy(X_test).type(torch.int64)\n",
    "y_test = torch.from_numpy(y_test).type(torch.int64)\n",
    "\n",
    "test_dl = DataLoader(TensorDataset(X_test, y_test), batch_size=BS, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "0.9991357787593624"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = learn.predict(test_dl)\n",
    "utils.accuracy(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mispredicted: 18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "sk    0.995694\n",
       "cs    0.997000\n",
       "ro    0.997845\n",
       "da    0.998000\n",
       "pl    0.998000\n",
       "lt    0.998000\n",
       "lv    0.998979\n",
       "et    0.999000\n",
       "sl    0.999000\n",
       "bg    1.000000\n",
       "pt    1.000000\n",
       "nl    1.000000\n",
       "hu    1.000000\n",
       "fr    1.000000\n",
       "fi    1.000000\n",
       "es    1.000000\n",
       "en    1.000000\n",
       "el    1.000000\n",
       "de    1.000000\n",
       "it    1.000000\n",
       "sv    1.000000\n",
       "Name: correct, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'] = [idx2lang[x] for x in utils.conv2np(preds)]\n",
    "test['correct'] = (test['pred'] == test['label'])*1\n",
    "inc_total = len(test.index)-sum(test['correct'])\n",
    "print(f\"Total number of mispredicted: {inc_total}\")\n",
    "test.groupby(by = 'label')['correct'].agg('mean').sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_incorrect(i = None, lang = None):\n",
    "    \n",
    "    flag = (test['correct']==0)\n",
    "    if lang is not None:\n",
    "        flag = flag  & (test['label']==lang)\n",
    "    if i is not None:\n",
    "        idx = test[flag].index[i]\n",
    "    else:\n",
    "        idx = test[flag].sample(1).index\n",
    "    print(f'class: {test.iloc[idx][\"label\"]}, ', end = \"\")\n",
    "    print(f'predicted: {test.iloc[idx][\"pred\"]}, ', end = \"\")\n",
    "    print(f'text: {utils.de_numericalize(X_test.numpy()[idx:(idx+1)], idx2word)}, ', end = \"\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: cs, predicted: sk, text: ['Ka≈æd√Ω <punct> kdo m√° zdrav√Ω rozum <punct> je pacifista <eos>'], \n",
      "\n",
      "class: cs, predicted: sk, text: ['<unk> k <num> <unk> se z√°kladnou RAF <unk> v Cambridgeshire <eos>'], \n",
      "\n",
      "class: cs, predicted: sk, text: ['Vl√°da zesiluje <unk> a <unk> opoziƒçn√≠ aktivisty <eos>'], \n",
      "\n",
      "class: da, predicted: es, text: ['De frems√¶tter en <unk> profeti <eos>'], \n",
      "\n",
      "class: da, predicted: en, text: ['Their will is the law <punct> not only at home <punct> but as to the concerns of every nation <eos> <eos> They have swept away the very constitutions under which the <unk>'], \n",
      "\n",
      "class: et, predicted: lt, text: ['<unk> <punct> kas <unk> oli sama <eos>'], \n",
      "\n",
      "class: lt, predicted: et, text: ['ƒÆ tai atkreipdƒómesƒØ Patrick Gaubert <eos>'], \n",
      "\n",
      "class: lt, predicted: et, text: ['≈†is <unk> <punct> pagrindinm≈´s≈≥ problema <eos>'], \n",
      "\n",
      "class: lv, predicted: et, text: ['JƒÅcer <punct> ka ≈°ie <unk> soƒºi <unk> <unk> <unk> <eos>'], \n",
      "\n",
      "class: pl, predicted: et, text: ['Obie nogi <unk> na <unk> <eos>'], \n",
      "\n",
      "class: pl, predicted: et, text: ['W skali roku wynosi on miliardy <eos>'], \n",
      "\n",
      "class: ro, predicted: es, text: ['Europa este un exerci≈£iu al responsabilitƒÉ≈£ii <eos>'], \n",
      "\n",
      "class: ro, predicted: es, text: ['<unk> este una <unk> <eos>'], \n",
      "\n",
      "class: sk, predicted: cs, text: ['Mysl√≠m <punct> ≈æe to je novinka <eos>'], \n",
      "\n",
      "class: sk, predicted: pl, text: ['<unk> <unk> <unk> <punct> nie <unk> <eos>'], \n",
      "\n",
      "class: sk, predicted: cs, text: ['<unk> <unk> <punct> rozprava <punct> <eos>'], \n",
      "\n",
      "class: sk, predicted: fr, text: ['<unk> znepokojenie <eos>'], \n",
      "\n",
      "class: sl, predicted: sv, text: ['<unk> posredovanje med vsemi stranmi <eos>'], \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(inc_total): print_incorrect(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time : 11.936473703384399 mins\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(f'Total time : {(end - start)/60} mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try with own example text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These examples are in English, German and Hungarian respectively\n",
    "own_examples = [\"Let's see if this sentence gets classified correctly.\", \n",
    " 'Das k√∂nnen wir auch ausprobieren',\n",
    " 'Ezt a sz√∂veget is megpr√≥b√°ljuk leford√≠tani.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_own(ex_list, learn_obj = learn, langmapper = idx2lang):\n",
    "    y = torch.zeros(len(ex_list))  # 1. Dummy y for data loader\n",
    "    exampl = np.array(list(map(utils.preprocess, ex_list)))  # 2. Preprocess, convert to numpy\n",
    "    idxs = utils.numericalize(exampl, word2idx)  # 3. Numericalize\n",
    "    idxs = torch.from_numpy(idxs).type(torch.int64) # 4. Convert to torch tensor\n",
    "    dl = DataLoader(TensorDataset(idxs, y), batch_size=BS, shuffle = False)  # 6. Put in dataloader\n",
    "    res = learn_obj.predict(dl)  # 7. Predict language index\n",
    "    res = [langmapper[x] for x in utils.conv2np(res)]  # 8. Map index to language\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "['en', 'de', 'hu']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_own(own_examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
